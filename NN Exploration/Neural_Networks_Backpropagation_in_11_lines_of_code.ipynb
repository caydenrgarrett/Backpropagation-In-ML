{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Bilayered Neural Network"
      ],
      "metadata": {
        "id": "H0j98yxm1Mr-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-69qVGVoXzu",
        "outputId": "a36a536a-586b-4489-ec18-f37634ec25d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output after training:\n",
            "[[0.00966449]\n",
            " [0.00786506]\n",
            " [0.99358898]\n",
            " [0.99211957]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sgmoid function\n",
        "def nonlin(x, deriv=False):\n",
        "  if (deriv==True):\n",
        "    return x * (1-x)\n",
        "  return 1 / (1+np.exp(-x))\n",
        "\n",
        "# Input dataset\n",
        "X = np.array([  [0,0,1],\n",
        "                [0,1,1],\n",
        "                [1,0,1],\n",
        "                [1,1,1] ])\n",
        "\n",
        "# Output dataset\n",
        "y = np.array([[0,0,1,1]]).T\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "syn0 = 2*np.random.random((3,1)) - 1\n",
        "\n",
        "for iter in range(10000):\n",
        "\n",
        "  # Forward Propagation\n",
        "  l0 = X\n",
        "  l1 = nonlin(np.dot(l0, syn0))\n",
        "\n",
        "  # By how much was missed?\n",
        "  l1_error = y - l1\n",
        "\n",
        "  # Multiply how much we missed,\n",
        "  # by the slope of the sigmoid values\n",
        "  l1_delta = l1_error * nonlin(l1, True)\n",
        "  syn0 += np.dot(l0.T,l1_delta)\n",
        "\n",
        "print(\"Output after training:\")\n",
        "print(l1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trilayered Neural Network"
      ],
      "metadata": {
        "id": "a5fMq_Ng1RBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def nonlin(x, deriv=False):\n",
        "  if(deriv==True):\n",
        "    return x * (1 - x)\n",
        "  return 1/ (1 + np.exp(-x))\n",
        "\n",
        "# Input dataset\n",
        "X = np.array([  [0,0,1],\n",
        "                [0,1,1],\n",
        "                [1,0,1],\n",
        "                [1,1,1] ])\n",
        "\n",
        "# Output dataset\n",
        "y = np.array([[0],\n",
        "              [1],\n",
        "              [1],\n",
        "              [0]])\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "# Randomly inititalize our weights with a mean of zero\n",
        "syn0 = 2*np.random.random((3,4)) - 1\n",
        "syn1 = 2*np.random.random((4,1)) - 1\n",
        "\n",
        "for j in range(60000):\n",
        "  # Feed forward through layers 0 through 2\n",
        "  l0 = X\n",
        "  l1 = nonlin(np.dot(l0,syn0))\n",
        "  l2 = nonlin(np.dot(l1,syn1))\n",
        "\n",
        "  # By how much did we miss our target value\n",
        "  l2_error = y - l2\n",
        "\n",
        "  if (j%10000) == 0:\n",
        "    print(\"Error:\", str(np.mean(np.abs(l2_error)))) # Changed + to , and made it a single argument\n",
        "\n",
        "\n",
        "  # Which direction is the actual target value,\n",
        "  # if unsure don't change that much\n",
        "  l2_delta = l2_error*nonlin(l2,deriv=True)\n",
        "\n",
        "  # How much did each l1 value contribute to the l2 error (according to weights)\n",
        "  l1_error = l2_delta.dot(syn1.T)\n",
        "  l1_delta = l1_error * nonlin(l1,deriv=True)\n",
        "\n",
        "  # update weights\n",
        "  syn1 += l1.T.dot(l2_delta)\n",
        "  syn0 += l0.T.dot(l1_delta) # Changed l0.dot to l0.T.dot\n",
        "\n",
        "print(\"\\n2nd output after training:\") # Added print statement for final output\n",
        "print(l2)"
      ],
      "metadata": {
        "id": "lvCrtBz_1Tig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a06173a-8ef1-48f6-fdba-ff3ff54d9d5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 0.4964100319027255\n",
            "Error: 0.008584525653247157\n",
            "Error: 0.0057894598625078085\n",
            "Error: 0.004629176776769985\n",
            "Error: 0.0039587652802736475\n",
            "Error: 0.003510122567861678\n",
            "\n",
            "2nd output after training:\n",
            "[[0.00260572]\n",
            " [0.99672209]\n",
            " [0.99701711]\n",
            " [0.00386759]]\n"
          ]
        }
      ]
    }
  ]
}